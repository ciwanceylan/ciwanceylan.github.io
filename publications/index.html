<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Ciwan Ceylan | publications</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.17.0/css/mdb.min.css" integrity="sha256-/SwJ2GDcEt5382i8zqDwl36VJGECxEoIcBIuoLmLR4g=" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css"  integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/publications/">

<!-- Open Graph -->


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light bg-white navbar-expand-sm fixed-top">
    <div class="container">
      
        
        <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Ciwan</span> Ceylan</a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          <li class="nav-item "><a class="nav-link" href="/assets/pdf/cv_ciwan_ceylan.pdf" target="_blank">CV </a></li>
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description"></p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2025</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="ceylan2025disobeying" class="col-sm-8">
    
      <span class="title">Disobeying Directions: Switching Random Walk Filters for Unsupervised Node Embedding Learning on Directed Graphs</span>
      <span class="author">
        
          
            
              
                <em>Ceylan, Ciwan</em>,
              
            
          
        
          
            
              
                
                  Ghoorchian, Kambiz,
                
              
            
          
        
          
            
              
                
                  and Kragic, Danica
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>Transactions on Machine Learning Research</em>
      
      
        2025
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
        
      [<a href="https://openreview.net/forum?id=yngjRgVA5A" target="_blank">URL</a>]
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Unsupervised learning of node embeddings for directed graphs (digraphs) requires careful handling to ensure unbiased modelling. This paper addresses two key challenges: (1) the obstruction of information propagation in random walk and message-passing methods due to local sinks, and (2) the representation of multiple multi-step directed neighbourhoods, arising from the distinction between in- and out-neighbours. These challenges are interconnectedâ€”local sinks can be mitigated by treating the graph as undirected, but this comes at the cost of discarding all directional information. We make two main contributions to unsupervised embedding learning for digraphs. First, we introduce ReachNEs (Reachability Node Embeddings), a general framework for analysing embedding models and diagnosing local sink behaviour on digraphs. ReachNEs defines the reachability filter, a matrix polynomial over normalized adjacency matrices that captures multi-step, direction-sensitive proximity. It unifies the analysis of message-passing and random walk models, making its insights applicable across a wide range of embedding methods. Second, we propose DirSwitch, a novel embedding model that resolves both local sink bias and neighbourhood multiplicity via switching random walks. These walks use directed edges for local steps, preserving directional structure, then switch to undirected edges for long-range transitions, enabling escape from local sinks and improving information dispersal. Empirical results on node classification benchmarks demonstrate that DirSwitch consistently outperforms state-of-the-art unsupervised digraph proximity embedding methods, and also serves as a flexible digraph extension for self-supervised graph neural networks.</p>
    </span>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="ceylan2025fullrank" class="col-sm-8">
    
      <span class="title">Full-Rank Unsupervised Node Embeddings for Directed Graphs via Message Aggregation</span>
      <span class="author">
        
          
            
              
                <em>Ceylan, Ciwan</em>,
              
            
          
        
          
            
              
                
                  Ghoorchian, Kambiz,
                
              
            
          
        
          
            
              
                
                  and Kragic, Danica
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>Transactions on Machine Learning Research</em>
      
      
        2025
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
        
      [<a href="https://openreview.net/forum?id=3ECbEZg2If" target="_blank">URL</a>]
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Linear message-passing models have emerged as compelling alternatives to non-linear graph neural networks for unsupervised node embedding learning, due to their scalability and competitive performance on downstream tasks. However, we identify a fundamental flaw in recently proposed linear models that combine embedding aggregation with concatenation during each message-passing iteration: rank deficiency. A rank-deficient embedding matrix contains column vectors which take arbitrary values, leading to ill-conditioning that degrades downstream task accuracy, particularly in unsupervised tasks such as graph alignment. We deduce that repeated embedding aggregation and concatenation introduces linearly dependent features, causing rank deficiency. To address this, we propose ACC (Aggregate, Compress, Concatenate), a novel model that avoids redundant feature computation by applying aggregation to the messages from the previous iteration, rather than the embeddings. Consequently, ACC generates full-rank embeddings, significantly improving graph alignment accuracy from 10% to 60% compared to rank-deficient embeddings, while also being faster to compute. Additionally, ACC employs directed message-passing and achieves node classification accuracies comparable to state-of-the-art self-supervised graph neural networks on directed graph benchmarks, while also being over 70 times faster on graphs with over 1 million edges.</p>
    </span>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2024</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="10.1145/3627673.3679994" class="col-sm-8">
    
      <span class="title">Scalable Unsupervised Feature Selection with Reconstruction Error Guarantees via QMR Decomposition</span>
      <span class="author">
        
          
            
              
                <em>Ceylan, Ciwan</em>,
              
            
          
        
          
            
              
                
                  Ghoorchian, Kambiz,
                
              
            
          
        
          
            
              
                
                  and Kragic, Danica
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>In Proceedings of the 33rd ACM International Conference on Information and Knowledge Management</em>
      
      
        2024
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
        
      [<a href="https://doi.org/10.1145/3627673.3679994" target="_blank">URL</a>]
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Unsupervised feature selection (UFS) methods have garnered significant attention for their capability to eliminate redundant features without relying on class label information. However, their scalability to large datasets remains a challenge, rendering common UFS methods impractical for such applications. To address this issue, we introduce QMR-FS, a greedy forward filtering approach that selects linearly independent features up to a specified relative tolerance, ensuring that any excluded features can be reconstructed from the retained set within this tolerance. This is achieved through the QMR matrix decomposition, which builds upon the well-known QR decomposition. QMR-FS benefits from linear complexity relative to the number of instances and boasts exceptional performance due to its ability to leverage parallelized computation on both CPU and GPU. Despite its greedy nature, QMR-FS achieves comparable classification and clustering accuracies across multiple datasets when compared to other UFS methods, while achieving runtimes approximately 10 times faster than recently proposed scalable UFS methods for datasets ranging from 100 million to 1 billion elements.</p>
    </span>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="pmlr-v139-ceylan21a" class="col-sm-8">
    
      <span class="title">Learning Node Representations Using Stationary Flow Prediction on Large Payment and Cash Transaction Networks</span>
      <span class="author">
        
          
            
              
                <em>Ceylan, Ciwan</em>,
              
            
          
        
          
            
              
                
                  FranzÃ©n, Salla,
                
              
            
          
        
          
            
              
                
                  and Pokorny, Florian T.
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>In Proceedings of the 38th International Conference on Machine Learning</em>
      
      
        2021
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
        
      [<a href="http://proceedings.mlr.press/v139/ceylan21a.html" target="_blank">URL</a>]
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Banks are required to analyse large transaction datasets as a part of the fight against financial crime. Today, this analysis is either performed manually by domain experts or using expensive feature engineering. Gradient flow analysis allows for basic representation learning as node potentials can be inferred directly from network transaction data. However, the gradient model has a fundamental limitation: it cannot represent all types of of network flows. Furthermore, standard methods for learning the gradient flow are not appropriate for flow signals that span multiple orders of magnitude and contain outliers, i.e. transaction data. In this work, the gradient model is extended to a gated version and we prove that it, unlike the gradient model, is a universal approximator for flows on graphs. To tackle the mentioned challenges of transaction data, we propose a multi-scale and outlier robust loss function based on the Student-t log-likelihood. Ethereum transaction data is used for evaluation and the gradient models outperform MLP models using hand-engineered and node2vec features in terms of relative error. These results extend to 60 synthetic datasets, with experiments also showing that the gated gradient model learns qualitative information about the underlying synthetic generative flow distributions.</p>
    </span>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="ceylan18a" class="col-sm-8">
    
      <span class="title">Conditional Noise-Contrastive Estimation of Unnormalised Models</span>
      <span class="author">
        
          
            
              
                <em>Ceylan, Ciwan</em>,
              
            
          
        
          
            
              
                
                  and Gutmann, Michael U.
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>In Proceedings of the 35th International Conference on Machine Learning</em>
      
      
        2018
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
        
      [<a href="http://proceedings.mlr.press/v80/ceylan18a.html" target="_blank">URL</a>]
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Many parametric statistical models are not properly normalised and only specified up to an intractable partition function, which renders parameter estimation difficult. Examples of unnormalised models are Gibbs distributions, Markov random fields, and neural network models in unsupervised deep learning. In previous work, the estimation principle called noise-contrastive estimation (NCE) was introduced where unnormalised models are estimated by learning to distinguish between data and auxiliary noise. An open question is how to best choose the auxiliary noise distribution. We here propose a new method that addresses this issue. The proposed method shares with NCE the idea of formulating density estimation as a supervised learning problem but in contrast to NCE, the proposed method leverages the observed data when generating noise samples. The noise can thus be generated in a semi-automated manner. We first present the underlying theory of the new method, show that score matching emerges as a limiting case, validate the method on continuous and discrete valued synthetic data, and show that we can expect an improved performance compared to NCE when the data lie in a lower-dimensional manifold. Then we demonstrate its applicability in unsupervised deep learning by estimating a four-layer neural image model.</p>
    </span>
    
  </div>
</div>
</li></ol>

  <h2 class="year">Preprint</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="ceylan2022digraphwavescalableextractionstructural" class="col-sm-8">
    
      <span class="title">Digraphwave: Scalable Extraction of Structural Node Embeddings via Diffusion on Directed Graphs</span>
      <span class="author">
        
          
            
              
                <em>Ceylan, Ciwan</em>,
              
            
          
        
          
            
              
                
                  Ghoorchian, Kambiz,
                
              
            
          
        
          
            
              
                
                  and Kragic, Danica
                
              
            
          
        
      </span>

      <span class="periodical">
      
      
        Preprint
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
        
      [<a href="https://arxiv.org/abs/2207.10149" target="_blank">URL</a>]
    
    
    
      [<a href="/assets/pdf/digraphwave.pdf" target="_blank">PDF</a>]
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Structural node embeddings, vectors capturing local connectivity information for each node in a graph, have many applications in data mining and machine learning, e.g., network alignment and node classification, clustering and anomaly detection. For the analysis of directed graphs, e.g., transactions graphs, communication networks and social networks, the capability to capture directional information in the structural node embeddings is highly desirable, as is scalability of the embedding extraction method. Most existing methods are nevertheless only designed for undirected graph. Therefore, we present Digraphwave â€“ a scalable algorithm for extracting structural node embeddings on directed graphs. The Digraphwave embeddings consist of compressed diffusion pattern signatures, which are twice enhanced to increase their discriminate capacity. By proving a lower bound on the heat contained in the local vicinity of a diffusion initialization node, theoretically justified diffusion timescale values are established, and Digraphwave is left with only two easy-to-interpret hyperparameters: the embedding dimension and a neighbourhood resolution specifier. In our experiments, the two embedding enhancements, named transposition and aggregation, are shown to lead to a significant increase in macro F1 score for classifying automorphic identities, with Digraphwave outperforming all other structural embedding baselines. Moreover, Digraphwave either outperforms or matches the performance of all baselines on real graph datasets, displaying a particularly large performance gain in a network alignment task, while also being scalable to graphs with millions of nodes and edges, running up to 30x faster than a previous diffusion pattern based method and with a fraction of the memory consumption. </p>
    </span>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="ceylan2022graphdcaframeworknode" class="col-sm-8">
    
      <span class="title">GraphDCA â€“ a Framework for Node Distribution Comparison in Real and Synthetic Graphs</span>
      <span class="author">
        
          
            
              
                <em>Ceylan, Ciwan</em>,
              
            
          
        
          
            
              
                
                  Poklukar, Petra,
                
              
            
          
        
          
            
              
                
                  Hultin, Hanna,
                
              
            
          
        
          
            
              
                
                  Kravchenko, Alexander,
                
              
            
          
        
          
            
              
                
                  Varava, Anastasia,
                
              
            
          
        
          
            
              
                
                  and Kragic, Danica
                
              
            
          
        
      </span>

      <span class="periodical">
      
      
        Preprint
      
      </span>
    

    <span class="links">
    
      [<a class="abstract">Abs</a>]
    
    
        
      [<a href="https://arxiv.org/abs/2202.03884" target="_blank">URL</a>]
    
    
    
      [<a href="/assets/pdf/graphdca.pdf" target="_blank">PDF</a>]
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>We argue that when comparing two graphs, the distribution of node structural features is more informative than global graph statistics which are often used in practice, especially to evaluate graph generative models. Thus, we present GraphDCA - a framework for evaluating similarity between graphs based on the alignment of their respective node representation sets. The sets are compared using a recently proposed method for comparing representation spaces, called Delaunay Component Analysis (DCA), which we extend to graph data. To evaluate our framework, we generate a benchmark dataset of graphs exhibiting different structural patterns and show, using three node structure feature extractors, that GraphDCA recognizes graphs with both similar and dissimilar local structure. We then apply our framework to evaluate three publicly available real-world graph datasets and demonstrate, using gradual edge perturbations, that GraphDCA satisfyingly captures gradually decreasing similarity, unlike global statistics. Finally, we use GraphDCA to evaluate two state-of-the-art graph generative models, NetGAN and CELL, and conclude that further improvements are needed for these models to adequately reproduce local structural features.</p>
    </span>
    
  </div>
</div>
</li></ol>


</div>


  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2025 Ciwan Ceylan.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
  </div>
</footer>



  </body>

  <!-- Load Core and Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.0/umd/popper.min.js" integrity="sha256-OH05DFHUWzr725HmuHo3pnuvUUn+TJuj8/Qz9xytFEw=" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.17.0/js/mdb.min.js"  integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />


<!-- Load KaTeX -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" integrity="sha256-V8SV2MO1FUb63Bwht5Wx9x6PVHNa02gv8BgH/uH3ung=" crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js" integrity="sha256-F/Xda58SPdcUCr+xhSGz9MA2zQBPb0ASEYKohl8UCHc=" crossorigin="anonymous"></script>
<script src="/assets/js/katex.js"></script>



<!-- Load Mansory & imagesLoaded -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="" crossorigin="anonymous"></script>
<script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>

<!-- Project Cards Layout -->
<script type="text/javascript">
  // Init Masonry
  var $grid = $('.grid').masonry({
    gutter: 10,
    horizontalOrder: true,
    itemSelector: '.grid-item',
  });
  // layout Masonry after each image loads
  $grid.imagesLoaded().progress( function() {
    $grid.masonry('layout');
  });
</script>







</html>
